import itertools
import scipy
import scipy.stats
import numpy as np
from bayesian_agents.rsaWorld import RSA_World
from model_wrapper.Model_adaptive import Model


class RSA:

    """
    RSA Class:
    :contains:
        - initialize_speakers: Setting up models for initial speakers + prior
        - speaker function: posterior distribution over tokens
        - listener function
        - util functions (memoize, flush_cache)
    """

    def __init__(
            self,
            vocabulary,
            seg_type="char",
            tf=False,
    ):

        self.tf = tf
        self.seg_type = seg_type
        self.char = self.seg_type = "char"

        # caches for memoization
        self._speaker_cache = {}
        self._listener_cache = {}

        if self.char:
            self.idx2seg = vocabulary.idx2word
            self.seg2idx = vocabulary.word2idx

    def initialize_speakers(self, model_path):
        """ initialize neural models for initial speakers + prior """

        self.initial_speakers = Model(
            dictionaries=(self.seg2idx, self.idx2seg), model_path=model_path
            )

    def flush_cache(self):

        self._speaker_cache = {}
        self._listener_cache = {}

    def memoize_speaker(f):
        def helper(self, state, world, depth):

            hashable_args = state, world, depth

            if hashable_args not in self._speaker_cache:
                self._speaker_cache[hashable_args] = f(
                    self, state, world, depth)
            # else: print("cached")
            return self._speaker_cache[hashable_args]
        return helper

    def memoize_listener(f):
        def helper(self, state, utterance, depth):

            hashable_args = state, utterance, depth

            if hashable_args not in self._listener_cache:
                self._listener_cache[hashable_args] = f(
                    self, state, utterance, depth)

            return self._listener_cache[hashable_args]
        return helper

    @memoize_speaker
    def speaker(self, state, world, depth):
        """
        :input: RSA State , RSA world, depth
        :returns: posterior for tokens

        probability distribution over utterances given referents
        """

        if depth == 0:
            # "literal speaker"
            # return caption generated by neural model
            #print("s0")
            return self.initial_speakers.forward(state=state, world=world)

        else:
            # use probability distribution over vocabulary
            # generated by neural model as prior
            prior = self.speaker(state, world, depth=0)

        if depth == 1:
            # "pragmatic speaker", based on feedback from literal listener
            scores = []
            # iterate through possible next utterances
            for k in range(prior.shape[0]):
                # get probability distribution over all possible images
                # given utterance k as next token from literal listener
                out = self.listener(state=state, utterance=k, depth=depth - 1)
                # append probability value for target image to scores list
                scores.append(
                    out[world.target, world.rationality, world.speaker])

            scores = np.asarray(scores)
            scores = scores * (self.initial_speakers.rationality_support[world.rationality])

            # compute posterior from prior and listener scores
            posterior = (scores + prior) - scipy.special.logsumexp(scores + prior)

            return posterior

        elif depth == 2:

            scores = []
            for k in range(prior.shape[0]):

                out = self.listener(state=state, utterance=k, depth=depth - 1)
                scores.append(
                    out[world.target, world.rationality, world.speaker])

            scores = np.asarray(scores)
            posterior = (scores + prior) - scipy.special.logsumexp(scores + prior)

            return posterior

    @memoize_listener
    def listener(self, state, utterance, depth):
        '''probability distribution over referents given utterance'''
        # the listener generates a conditional probability distribution
        # over possible target images given a utterance
        #
        # method:
        #   1) iterate through possible target images
        #   2) get probability distribution over vocabulary
        #       given a specific target image from speaker,
        #       select probability value for the given utterance
        #   3) return probability distribution for every image
        #       that utterance is chosen

        # get state from previous time step, initialize score array
        world_prior = state.world_priors[state.timestep - 1]
        scores = np.zeros((world_prior.shape))
        # iterate through all possible images
        for n_tuple in itertools.product(*[list(range(x)) for x in world_prior.shape]):
            # point to the image i currently in focus
            world = RSA_World(target=n_tuple[state.dim["image"]],
                              rationality=n_tuple[state.dim["rationality"]], speaker=n_tuple[state.dim["speaker"]])

            # note THAT NOT DEPTH-1 HERE
            # get probability distribution over possible next tokens
            # from speaker given the target image i
            out = self.speaker(state=state, world=world, depth=depth)

            # save probability value for the given utterance given i
            scores[n_tuple] = out[utterance]

        # apply listener rationality (1 by default)
        scores = scores * state.listener_rationality
        world_posterior = (scores + world_prior) - scipy.special.logsumexp(scores + world_prior)
        return world_posterior

    def listener_simple(self, state, utterance, depth):

        # base case listener is either neurally trained,
        # or inferred from neural s0, given the state's current prior on images

        world_prior = state.world_priors[state.timestep - 1]
        assert world_prior.shape == (2, 1, 1)
        print("world prior", np.exp(world_prior))

        # I could write: itertools product axes
        scores = np.zeros((2, 1, 1))
        for i in range(2):
            world = RSA_World(target=i, rationality=0, speaker=0)

            # note THAT NOT DEPTH-1 HERE
            out = self.speaker(state=state, world=world, depth=depth)

            scores[i] = out[utterance]

        scores = scores * state.listener_rationality
        world_posterior = (scores + world_prior) - \
            scipy.special.logsumexp(scores + world_prior)

        return world_posterior
